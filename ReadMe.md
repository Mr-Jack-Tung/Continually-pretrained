
- Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order (https://arxiv.org/abs/2404.00399)
- Continual Pre-Training of Large Language Models: How to (re)warm your model? (https://arxiv.org/abs/2308.04014)
- Continual Pre-training of Language Models (https://arxiv.org/abs/2302.03241)
- Adapting a Language Model While Preserving its General Knowledge (https://arxiv.org/abs/2301.08986)

